{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5fa17qJB63S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "QvCGe4Cj67bx",
        "outputId": "4cf710d1-efed-44a6-c448-ca856f484016"
      },
      "outputs": [],
      "source": [
        "base = pd.read_csv(\"basePreProcessada2Balanceada.csv\") #Base com melhor resultado nos testes\n",
        "#base_small = base.sample(100000) #Uso temporário para mais rápida avaliação dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Abordagem de random sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_trainRS,x_testRS,y_trainRS,y_testRS = train_test_split(base.drop(['CLASSI_FIN'], axis=1), base['CLASSI_FIN'], test_size=0.3)\n",
        "\n",
        "#Abordagem de cross validation\n",
        "y_train = base['CLASSI_FIN']\n",
        "x_train = base.drop(['CLASSI_FIN'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKhlepLCB2oJ"
      },
      "source": [
        "Rede Neural (Multilayer Perceptron - MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6uJgPMWPJQu"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Controle\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 1\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model1 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(50, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history1 = model1.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 2\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model2 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model2.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history2= model2.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 3\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model3 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(200, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(50, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model3.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history3 = model3.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 4\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model4 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(200, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model4.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history4 = model4.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 5\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model5 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model5.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history5 = model5.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 6\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model6 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model6.compile(loss=\"binary_crossentropy\", loss_weights = 0.001, #Especificação pede para definir taxa de aprendizado (loss_weights) em 0.001 mas não indica qual a função de loss! - VERIFICAR\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history6 = model6.fit(x_trainRS, y_trainRS, batch_size=32, epochs=50, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 7\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model7 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model7.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history7 = model7.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 8\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model8 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"gelu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model8.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history8 = model5.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 9\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model9 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"linear\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model9.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history9 = model9.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 10\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model10 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"elu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model10.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history10 = model10.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 11\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model11 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"leaky_relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model11.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history11 = model11.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 12\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model12 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model12.compile(loss=\"binary_crossentropy\", loss_weights = 0.01,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history12 = model12.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 13\n",
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model13 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "model13.compile(loss=\"binary_crossentropy\", loss_weights = 0.1,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "history13 = model13.fit(x_trainRS, y_trainRS, batch_size=32, epochs=20, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAjvaRY2CMKf"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCefpcqbMmfo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhorSlLcCM5m"
      },
      "outputs": [],
      "source": [
        "#Controle\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric='euclidean')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreCtrlKNN = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#scoreCrtl = np.mean(scores)\n",
        "#print(scoreCrtl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 1\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric='manhattan')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT1KNN = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#scoreT1 = np.mean(scores)\n",
        "#print(scoreT1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"SCORE CONTROLE: {scoreCtrlKNN}\\nSCORE TESTE1: {scoreT1KNN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 2\n",
        "def hassanat_dist_metric(df1, df2):\n",
        "    dist_list = []\n",
        "    total = 0\n",
        "    \n",
        "    for x in range(len(df1)):\n",
        "        data1 = np.array(df1)[x]\n",
        "        data2 = np.array(df2)[x]\n",
        "        \n",
        "        min_ = min(data1, data2)\n",
        "        max_ = max(data1, data2)\n",
        "        \n",
        "        if min_ >= 0:\n",
        "            dist = 1-( (1+min_)/(1+max_) )\n",
        "            dist_list.append(dist)\n",
        "\n",
        "        else:\n",
        "            dist = 1-( (1+min_ + np.abs(min_))/(1+max_+np.abs(min_) ) )\n",
        "            dist_list.append(dist)\n",
        "    \n",
        "    total = np.sum(dist_list)\n",
        "    return total\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric= hassanat_dist_metric)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT2KNN = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#scoreT2 = np.mean(scores)\n",
        "#print(scoreT2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 3\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric='hamming')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT3KNN = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#scoreT3 = np.mean(scores)\n",
        "#print(scoreT3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"SCORE CONTROLE: {scoreCtrlKNN}\\nSCORE TESTE1: {scoreT1KNN}\\nSCORE TESTE2: {scoreT2KNN}\\nSCORE TESTE3: {scoreT3KNN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 4\n",
        "classifier = KNeighborsClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [5, 2, 10, 50],\n",
        "    'metric': ['euclidean'],\n",
        "    'weights': ['uniform']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=2) #TESTAR\n",
        "grid_search.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "scoreT4KNN = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "y_pred = grid_search.best_estimator_.predict(x_testRS)\n",
        "scoreT4BestKNN = accuracy_score(y_testRS, y_pred)\n",
        "print(scoreT4BestKNN)\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TESTE 4 SCORES:\\n{scoreT4KNN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS3Mal2wPVcm"
      },
      "source": [
        "Logistic Regression (Regressão Logística)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4T18sVTPfvC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yFxyN6KSYsf"
      },
      "outputs": [],
      "source": [
        "#Controle\n",
        "classifier = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=100)\n",
        "classifier.fit(x_trainRS, y_trainRS) \n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreCtrlLR = accuracy_score(y_testRS, y_pred)\n",
        "print(scoreCtrlLR)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 1\n",
        "classifier = LogisticRegression(penalty='l2', solver='sag', max_iter=100)\n",
        "classifier.fit(x_trainRS, y_trainRS) \n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT1LR = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 2\n",
        "classifier = LogisticRegression(penalty='l2', solver='newton-cholesky', max_iter=100)\n",
        "classifier.fit(x_trainRS, y_trainRS) \n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT2LR = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 3\n",
        "classifier = LogisticRegression(penalty='l2', solver='liblinear', max_iter=100)\n",
        "classifier.fit(x_trainRS, y_trainRS) \n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT3LR = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"SCORE CONTROLE: {scoreCtrlLR}\\nSCORE TESTE1: {scoreT1LR}\\nSCORE TESTE2: {scoreT2LR}\\nSCORE TESTE3: {scoreT3LR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 4\n",
        "classifier = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "classifier.fit(x_trainRS, y_trainRS) \n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT4LR = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TESTE 4 SCORES:\\n{scoreT4LR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 5\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs'],\n",
        "    'max_iter': [100, 200, 500, 1000, 5000],\n",
        "    'C': [0.2, 0.5, 0.7, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=2)\n",
        "grid_search.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "scoreT5LR = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "y_pred = grid_search.best_estimator_.predict(x_testRS)\n",
        "scoreT5BestLR = accuracy_score(y_testRS, y_pred)\n",
        "print(scoreT5BestLR)\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoreT5LR.sort_values(by='rank_test_score', inplace=True)\n",
        "scoreT5LR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLIfgY_42LiP"
      },
      "source": [
        "Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53hy3Y822QXm"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn7bpCxE3ccv"
      },
      "outputs": [],
      "source": [
        "#Controle\n",
        "classifier = DecisionTreeClassifier(criterion='entropy',  max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreCtrlDT = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 1\n",
        "classifier = DecisionTreeClassifier(criterion='gini',  max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT1DT = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 2\n",
        "classifier = DecisionTreeClassifier(criterion='log_loss',  max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS)\n",
        "\n",
        "scoreT2DT = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"SCORE CONTROLE: {scoreCtrlDT}\\nSCORE TESTE1: {scoreT1DT}\\nSCORE TESTE2: {scoreT2DT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 3\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'min_samples_leaf': [1, 5, 10, 50, 100],\n",
        "    'max_depth': [None, 50, 100, 500],\n",
        "    'criterion': ['entropy', 'log_loss'],\n",
        "    'min_samples_split': [2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=2) #TESTAR\n",
        "grid_search.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "scoreT3DT = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "y_pred = grid_search.best_estimator_.predict(x_testRS)\n",
        "scoreT3BestDT = accuracy_score(y_testRS, y_pred)\n",
        "print(scoreT3BestDT)\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scoreT3DT.sort_values(by='rank_test_score', inplace=True)\n",
        "scoreT3DT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pORxcdVn4q39"
      },
      "source": [
        "Random Forest (Floresta Aleatória)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmZ_11wg4uTN"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpEseOrd6Y5K"
      },
      "outputs": [],
      "source": [
        "#Controle\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreCtrlRF = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 1\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='gini')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT1RF = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 2\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='log_loss')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT2RF = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"SCORE CONTROLE: {scoreCtrlRF}\\nSCORE TESTE1: {scoreT1RF}\\nSCORE TESTE2: {scoreT2RF}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 3\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='log_loss', max_features='log2')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT3RF = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 4\n",
        "classifier = RandomForestClassifier(n_estimators=100, criterion='log_loss', max_features=10)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "scoreT4RF = accuracy_score(y_testRS, y_pred)\n",
        "\n",
        "#scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "#print(scores)\n",
        "#print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Teste 5\n",
        "classifier = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [500, 1000, 2000],\n",
        "    'criterion': ['log_loss'],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=2) #TESTAR\n",
        "grid_search.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "scoreT5RF = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "y_pred = grid_search.best_estimator_.predict(x_testRS)\n",
        "scoreT5BestRF = accuracy_score(y_testRS, y_pred)\n",
        "print(scoreT5BestRF)\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"TESTE 3 SCORE: {scoreT3RF}\\nTESTE 4 SCORE: {scoreT4RF}\\nTESTE 5 SCORES (reduced set):\\n\")\n",
        "scoreT5RF.sort_values(by='rank_test_score', inplace=True)\n",
        "scoreT5RF"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
