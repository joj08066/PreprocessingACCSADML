{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5fa17qJB63S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "QvCGe4Cj67bx",
        "outputId": "4cf710d1-efed-44a6-c448-ca856f484016"
      },
      "outputs": [],
      "source": [
        "base = pd.read_csv(\"basePreProcessada2Balanceada.csv\")\n",
        "#base_small = base.sample(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Abordagem de random sampling\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_trainRS,x_testRS,y_trainRS,y_testRS = train_test_split(base.drop(['CLASSI_FIN'], axis=1), base['CLASSI_FIN'], test_size=0.3)\n",
        "\n",
        "#Abordagem de cross validation\n",
        "y_train = base['CLASSI_FIN']\n",
        "x_train = base.drop(['CLASSI_FIN'], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKhlepLCB2oJ"
      },
      "source": [
        "Rede Neural (Multilayer Perceptron - MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6uJgPMWPJQu"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zon61iu76ErZ"
      },
      "outputs": [],
      "source": [
        "x = x_trainRS.shape[1] #Quantidade de colunas do X de treinamento (entradas)\n",
        "model1 = keras.models.Sequential([\n",
        "  keras.Input(shape=[x]),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(100, activation=\"relu\"),\n",
        "  keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU93f4zoDZ0F"
      },
      "outputs": [],
      "source": [
        "model1.compile(loss=\"binary_crossentropy\", loss_weights = 0.001,\n",
        "optimizer=\"adam\",\n",
        "metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOZV6xqzDeOD"
      },
      "outputs": [],
      "source": [
        "history1 = model1.fit(x_trainRS, y_trainRS, batch_size=32, epochs=200, validation_data=(x_testRS, y_testRS)) #batch_size=32 é o padrão coloquei apenas para ficar mais claro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(history1.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAjvaRY2CMKf"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCefpcqbMmfo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhorSlLcCM5m"
      },
      "outputs": [],
      "source": [
        "#Na especificação temos \"Peso das amostras: Uniforme\" que significa que devemos implementar uma KNN não uma DWNN em que vizinhos mais próximos tem pesos maiores. Uniform é o padrão na biblioteca, coloquei apenas para ficar mais claro\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric='euclidean')\n",
        "classifier.fit(x_train, y_train) #Compõe o espaço para o calculo sobre futuras entradas\n",
        "\n",
        "scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors = 5, weights='uniform', metric='euclidean')\n",
        "classifier.fit(x_trainRS, y_trainRS) #Compõe o espaço para o calculo sobre futuras entradas\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "simple_score = accuracy_score(y_testRS, y_pred)\n",
        "print(simple_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS3Mal2wPVcm"
      },
      "source": [
        "Logistic Regression (Regressão Logística)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4T18sVTPfvC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yFxyN6KSYsf"
      },
      "outputs": [],
      "source": [
        "classifier = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=100)\n",
        "classifier.fit(x_train, y_train) #Assim como no KNN as coordenadas são dadas pelo valor dos atributos e o y_train é necessário para entender qual lado da reta o ponto pertence\n",
        "\n",
        "scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 5 divisões, retornando um score muito mais preciso\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=100)\n",
        "classifier.fit(x_trainRS, y_trainRS) #Assim como no KNN as coordenadas são dadas pelo valor dos atributos e o y_train é necessário para entender qual lado da reta o ponto pertence\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "simple_score = accuracy_score(y_testRS, y_pred)\n",
        "print(simple_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLIfgY_42LiP"
      },
      "source": [
        "Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53hy3Y822QXm"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn7bpCxE3ccv"
      },
      "outputs": [],
      "source": [
        "classifier = DecisionTreeClassifier(criterion='entropy',  max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "print(scores)\n",
        "print(np.mean(scores))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = DecisionTreeClassifier(criterion='entropy',  max_depth=None, min_samples_split=2, min_samples_leaf=1)\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "simple_score = accuracy_score(y_testRS, y_pred)\n",
        "print(simple_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pORxcdVn4q39"
      },
      "source": [
        "Random Forest (Floresta Aleatória)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmZ_11wg4uTN"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpEseOrd6Y5K"
      },
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "scores = cross_val_score(classifier, x_train, y_train, cv=5) #Roda cross-validation com 10 divisões, retornando um score muito mais preciso\n",
        "print(scores)\n",
        "print(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
        "classifier.fit(x_trainRS, y_trainRS)\n",
        "\n",
        "y_pred = classifier.predict(x_testRS) #Teste do modelo obtendo os resultados preditos para o X de teste\n",
        "\n",
        "simple_score = accuracy_score(y_testRS, y_pred)\n",
        "print(simple_score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
